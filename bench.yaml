# GPU Roofline Benchmark Configuration

# Global settings
defaults:
  precision: [float32]  # float16, float32, float64
  warmup_runs: 3
  measurement_runs: 10
  
# Kernel configurations
kernels:
  saxpy:
    description: "SAXPY: Y = αX + Y (memory-bound)"
    operational_intensity: 0.25  # 2 FLOPs / 8 bytes
    sizes: [1M, 4M, 16M, 64M, 256M]
    alpha: 2.5
    
  triad:
    description: "Triad: A = B + α·C (memory-bound)" 
    operational_intensity: 0.167  # 2 FLOPs / 12 bytes
    sizes: [1M, 4M, 16M, 64M, 256M]
    alpha: 3.0
    
  sgemm:
    description: "Single-precision matrix multiplication (compute-bound)"
    operational_intensity: 85.33  # 2N³ FLOPs / 3N² * 4 bytes (for N=512)
    sizes: [256, 512, 1024, 2048]  # Square matrix dimensions
    alpha: 1.0
    beta: 0.0
    
  wmma_gemm:
    description: "Tensor Core GEMM using WMMA (compute-bound)"
    operational_intensity: 85.33
    sizes: [256, 512, 1024, 2048]
    precision: [float16]  # Tensor cores work with FP16
    alpha: 1.0
    beta: 0.0

# Device-specific overrides
device_overrides:
  cuda:
    # CUDA-specific settings
    saxpy:
      block_size: 256
      grid_size: auto  # Computed based on size
    sgemm:
      tile_size: 16
      
  metal:
    # Metal-specific settings  
    saxpy:
      threads_per_threadgroup: 256
      threadgroups_per_grid: auto
    sgemm:
      tile_size: 16
      
  cpu:
    # CPU/OpenMP settings
    num_threads: auto  # Use all available cores